---
title: "Politics analysis computation"
author: "Mattia Egloff"
date: "18/03/2020"
output: html_document
params:
  datasets:
    - "swiss_legislator_49"
    - "swiss_legislator_50"
    - "italian_legislator_17"
    - "italian_legislator_18"
  selected_option: 2
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
option <- params$selected_option
```

## Option: `r I(option)` 


```{r include=FALSE}
devtools::load_all()
library("tidyverse")
library("Rtsne")
library(simdiversity.entropy)
library(simdiversity.data.politics)
library(simdiversity.weighted.mds)

datasets <- params$datasets
```

Get swsiss and italian data:
```{r include=FALSE}
data <- list()
dissimilarites <- list()
weights <- list()
w_disputedness <- list()
scores_matrix <- list()

for (dataset in datasets) {
  dissimilarites[[dataset]] <- dataset_from_str(
    paste0(dataset, "__", option, "__D_final")
  )

  weights[[dataset]] <- dataset_from_str(
    paste0(dataset, "__", option, "__weight")
  )

  data[[dataset]] <- dataset_from_str(dataset)

  w_disputedness[[dataset]] <- dataset_from_str(
    paste0(
      dataset, "__", option,
      "__weighted_vote_disputedness"
    )
  )

  s_matrix <- dataset_from_str(
    paste0(dataset, "__", option, "__scores_matrix")
  )
  null_votes <- dataset_from_str(
    paste0(dataset, "__", option, "__null_votes")
  )
  null_councilors <- dataset_from_str(
    paste0(dataset, "__", option, "__null_councilors")
  )
  if (!is_empty(null_votes)) {
    s_matrix <-
      s_matrix[, !colnames(s_matrix) %in% null_votes]
  }
  if (!is_empty(null_councilors)) {
    s_matrix <-
      s_matrix[!rownames(s_matrix) %in% null_councilors, ]
  }
  scores_matrix[[dataset]] <- s_matrix
}


results <- list()
```

### Basic infos

```{r}
for (dataset in datasets) {
  print(paste(
    "Dataset :", dataset, "\ncontains:\n -",
    nrow(scores_matrix[[dataset]]), "Councillors\n -",
    ncol(scores_matrix[[dataset]]), "Votes\n\n"
  ))
}
```

# Vote means and variance


```{r}
for (dataset in datasets) {
  means_and_vars <- column_means_and_vars(scores_matrix[[dataset]])
  table(means_and_vars$Mean_votes)
  hist(
    means_and_vars$Votes_variance,
    main = paste(dataset, "-", "option", option),
    cex.lab = 2,
    xlab = expression("vote variance " * v[l]),
    cex.main = 2,
    breaks = 20
  )
}
```

# Vote disputedness

```{r}

for (dataset in datasets) {
  hist(
    w_disputedness[[dataset]],
    breaks = 20,
    xlab = expression("weighted disputedness " * pi[k]),
    ylab = "count",
    cex.axis = 2,
    cex.lab = 2,
    main = paste(dataset, "-", "option", option)
  )
}
```



# MDS

```{r }

for (dataset in datasets) {
  results[[dataset]]$mds <- weighted_mds(
    dissimilarites[[dataset]], weights[[dataset]]
  )
}
```

\newpage
## MDS by Gender Dimension 1 and 2
```{r }

for (dataset in datasets) {
  gender <- data[[dataset]]$Councillors$gender
  labels <- data[[dataset]]$Councillors$names
  plot.mds(
    results[[dataset]]$mds,
    c(1, 2),
    group_by = gender,
    labels = labels,
    main = paste("Gender", gsub("_", " ", dataset), "Option", option)
  )
}
```

\newpage
## MDS by Gender Dimension 3 and 4

```{r }

for (dataset in datasets) {
  gender <- data[[dataset]]$Councillors$gender
  labels <- data[[dataset]]$Councillors$names

  plot.mds(
    results[[dataset]]$mds,
    c(3, 4),
    group_by = gender,
    labels = labels,
    main = paste("Gender", gsub("_", " ", dataset), "Option", option)
  )
}
```

\newpage
## MDS by Party Dimension 1 and 2

```{r }

for (dataset in datasets) {
  party <- data[[dataset]]$Councillors$party
  labels <- data[[dataset]]$Councillors$names

  plot.mds(
        results[[dataset]]$mds,
    c(1, 2),
    group_by = party,
    labels = labels,
    main = paste("Party", gsub("_", " ", dataset), "Option", option)
  )
}
```

\newpage
## MDS by Party Dimension 3 and 4

```{r }

for (dataset in datasets) {
  party <- data[[dataset]]$Councillors$party
  labels <- data[[dataset]]$Councillors$names

  plot.mds(
        results[[dataset]]$mds,
    c(3, 4),
    group_by = party,
    labels = labels,
    main = paste("Party", gsub("_", " ", dataset), "Option", option)
  )
}
```

\newpage
## MDS by Region Dimension 1 and 2

```{r }
for (dataset in datasets) {
  region <- data[[dataset]]$Councillors$region
  labels <- data[[dataset]]$Councillors$names

  plot.mds(
    results[[dataset]]$mds,
    c(1, 2)
    group_by = region,
    labels = labels,
    main = paste("Region", gsub("_", " ", dataset), "Option", option)
  )
}
```

\newpage
## MDS by Region Dimension 3 and 4

```{r }
for (dataset in datasets) {
  region <- data[[dataset]]$Councillors$region
  labels <- data[[dataset]]$Councillors$names

  plot.mds(
    results[[dataset]]$mds.Xtilde, results[[dataset]]$mds.lambda,
    c(3, 4), weights[[dataset]],
    group_by = region,
    labels = labels,
    main = paste("Region", gsub("_", " ", dataset), "Option", option)
  )
}
```


\newpage
## TSNE

```{r }
for (dataset in datasets) {
  party <- data[[dataset]]$Councillors$party
  labels <- data[[dataset]]$Councillors$names

  results[[dataset]]$tsne_D <- Rtsne(
    dissimilarites[[dataset]],
    is_distance = TRUE
  )
  plot.tsne(
    results[[dataset]]$tsne_D$Y,
    weights[[dataset]],
    group_by = party,
    labels = labels,
    main = paste(
      "Tsne Distance: Party", gsub("_", " ", dataset), "Option", selected_option
    )
  )
}
```

\newpage

# Party similarity

```{r }
################ betwen parties ################

for (dataset in datasets) {
  results[[dataset]]$paries <- group_mesures(
    dissimilarites[[dataset]],
    weights[[dataset]],
    data[[dataset]]$Councillors$party
  )
}
```

# Consensual Votes

```{r }

for (dataset in datasets) {
  scores <- scores_matrix[[dataset]]
  propYES <- apply(scores, 2, function(vote_epressions) {
    sum(vote_epressions, na.rm = T) / sum(1 - is.na(vote_epressions))
  })
  propNO <- apply(scores, 2, function(vote_epressions) {
    sum(as.numeric(vote_epressions == 0), na.rm = T) / sum(1 - is.na(vote_epressions))
  })
  hist(propYES, breaks = 50)
  sum(as.numeric(propNO == 0))
}
```

# Entropy

```{r }
############ Entropies on the final dissimilarities d ############
for (dataset in datasets) {
  results[[dataset]]$entropy <- entropy(
    dissimilarites[[dataset]], weights[[dataset]]
  )
  print(paste(dataset, "entropy:", results[[dataset]]$entropy))
}
```

# Effective Entropy

```{r }


for (dataset in datasets) {
results[[dataset]]$effective_entropy <- effective_entropy(
  dissimilarites[[dataset]], weights[[dataset]],
  Nloop = 200, Nfine = 1200,
  pa = -3, pb = 3, power_crit = -0.115148
)

```

```{r }
# ########### PLOTS INTERESSANTS ###
# ## plot(beta_rel,rhoS[,i])
# ## ou bien, pour aller plus vite
for (dataset in datasets) {
 
  ee <- results[[dataset]]$effective_entropy
  is_not_null = which(colSums(ee$rho) > 0)
   par(mar = c(4.1,5.1,0.5,0.5))
  plot(ee$rho, main = paste(dataset,  "rho"))
   par(mar = c(4.1,5.1,0.5,0.5))
  plot(ee$beta_rel, main = paste(dataset, "beta_rel"))
   par(mar = c(4.1,5.1,0.5,0.5))
  plot(ee$R, main = paste(dataset, "R"))
   par(mar = c(4.1,5.1,0.5,0.5))
  plot(ee$E, main = paste(dataset, "E"))
     par(mar = c(4.1,5.1,0.5,0.5))
  matplot(ee$Ty, main = paste(dataset, "Ty"), type = "s")
       par(mar = c(4.1,5.1,0.5,0.5))
  matplot(ee$beta_rel,cbind(ee$E,ee$R,ee$H),type =  c("l"),lwd=c(2,2,2),col=c(1,1,1),log = "x")
}

```

```{r, incluede=FALSE, fig.show='hold', fig.width=20, fig.height=20, out.width="25%"}
for (dataset in datasets) {
  ee <- results[[dataset]]$effective_entropy
  for (i in nrow(ee$rho)){
    matplot(ee$beta_rel, ee$rho[i,],log="x",type="l", verbode = TRUE)
  }
}
```

```{r, incluede=FALSE, eval=FALSE}
# matplot(ee$beta_rel,cbind(ee$rho[,7],ee$rho[,21]),type="l",log="x")
# 
# # ## monotone (avec concavite pour rho(beta)>0)= pour i=1 ?? 13,15 ?? 22 ?? 39,42 ?? 47, 49,50,53 ?? 67, 69 ?? 72, 74
# # ## non-monotone pour i=14,21,
# # ## limite (rebond, brisant la concavite) pour i=9,40,41,48,51, 52,68 , 73
# 
# # ## figure 1
# par(mar=c(4.1,5.1,0.5,0.5))
# plot(ee$beta_rel,ee$rho[,16],type="l", xlab=expression(paste(beta[rel],"          temp??rature inverse")), ylab=expression(paste(r[j],"          poids du percept")),cex.lab=2,cex.axis=1.5,log = "x",lwd=2)
# legend(x=5e-06, y=0.0055, legend="Rural African American Vernacular English", lty=1:2, cex=1.6,box.lty=0)
# 
# # ## figure 2
# par(mar=c(4.1,5.1,0.5,0.5))
# matplot(ee$beta_rel,cbind(ee$rho[,3],ee$rho[,2],ee$rho[,6]),log="x",type="l",xlab=expression(paste(beta[rel],"          temp??rature inverse")), ylab=expression(paste(r[j],"          poids du percept")),lty=c("dotted","dashed","solid"),col=c("black", "black","black"),cex.lab=2,cex.axis=1.5,lwd=2)
# # legend(x=8e-05, y=0.0085, legend=c("Irish English","Scottish English","English dialects in the North of England"), lty=c(3,2,1), cex=1.6,box.lty=0)
# 
# # ## figure 3
# par(mar=c(4.1,5.1,0.5,0.5))
# matplot(ee$beta_rel,cbind(ee$rho[,51],ee$rho[,41],ee$rho[,52]),log="x",type="l",xlab=expression(paste(beta[rel],"          temp??rature inverse")), ylab=expression(paste(r[j],"          poids du percept")),lty=c("dotted","dashed","solid"),col=c("black", "black","black"),cex.lab=2,cex.axis=1.4,lwd=2)
# # legend(x=5e-05, y=0.13, legend=c("Indian English","Nigerian Pidgin","Pakistani English"), lty=c(3,2,1), cex=1.8,box.lty=0)
# 
# # ## figure 4
# par(mar=c(4.1,5.1,0.5,0.5))
# plot(ee$beta_rel,ee$rho[,21],type="l", xlab=expression(paste(beta[rel],"          temp??rature inverse")), ylab=expression(paste(r[j],"          poids du percept")),cex.lab=2,cex.axis=1.5,log = "x",lwd=2)
# # legend(x=3e-06, y=0.9, legend="Chicano English", lty=1:2, cex=2,box.lty=0)
# 
# dim(ee$rho)
# apply(ee$rho,1,min)  ## donne min_a(rho_a) pour chaque beta, et permet de determiner beta_L: c'est l'iteration 220 pour Nfine= 301
# ee$beta_rel[220]       ##  = 12.8825
# which.min(ee$rho[220,]) ##  = 16
# ee$data$Variety[16] ## Rural African American Vernacular English
# 
# par(mar=c(4.1,5.1,0.5,0.5))
# plot(ee$beta_rel,ee$Ty,type="s", xlab=expression(beta[rel]), ylab=expression(paste(N[eff],"          number of effective types")), cex.lab=1.5,log = "x")
# 
# plot(ee$beta_rel,ee$E,type="l", xlab=expression(paste(beta[rel],"          inverse temperature")), ylab=expression(paste(E,"          effective entropy")), cex.lab=1.5,log = "x")
# 
# plot(ee$beta_rel,ee$E,type="l", xlab=expression(paste(beta[rel],"          inverse temperature")), ylab=expression(paste(E,"          effective entropy")), cex.lab=1.5,log = "x")
# #
# Shannon=-sum(weights[[dataset]]*log(weights[[dataset]]))
# H=rep(Shannon,length(power_selection))  # a constant equal to Shannon entropy
# #
# par(mar=c(4.1,5.1,0.5,0.5))
# matplot(ee$beta_rel,cbind(ee$E,ee$R,H),type =  c("l"),lwd=c(2,2,2),col=c(1,1,1),log = "x",xlab=expression(paste(beta[rel],"          inverse temperature")), ylab="diversity measures : E, R and H",cex.lab=1.5)
# #
# plot(ee$beta_rel,ee$Ty,type="s", xlab=expression(paste(beta[rel],"          inverse temperature")), ylab=expression(paste(N[eff],"          number of identified categories")), cex.lab=1.5,log = "x")
# }
```



